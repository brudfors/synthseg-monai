{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SynthSeg testing in MONAI\n",
    "\"\"\"\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.distributed as dist\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityd,\n",
    "    ResizeWithPadOrCropd,\n",
    "    RandAffined,\n",
    "    Invertd,\n",
    "    RandZoomd,\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader, decollate_batch, TestTimeAugmentation\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils import set_determinism\n",
    "from monai.utils import first\n",
    "\n",
    "import transforms_synthseg as transforms\n",
    "import utils_synthseg as utils\n",
    "\n",
    "seed = 0\n",
    "set_determinism(seed=seed)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = True\n",
    "if testing:\n",
    "    spatial_size = (96,) * 3\n",
    "    patch_size = None\n",
    "    dout = \"./results-testing\"\n",
    "else:    \n",
    "    spatial_size = (256,) * 3\n",
    "    patch_size = (160,) * 3\n",
    "    dout = \"./results\"\n",
    "dir_data = \"./data/neurite_10\"\n",
    "model_pth = os.path.join(dout, 'model_best.pth')\n",
    "model_pth = None if not os.path.exists(model_pth) else model_pth\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [str(f) for f in sorted(Path(dir_data).rglob('orig.nii.gz'))]\n",
    "labels = [str(f) for f in sorted(Path(dir_data).rglob('seg35.nii.gz'))]\n",
    "val_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(images, labels)] \n",
    "val_files = [val_files[0]]\n",
    "print(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\", lazy=True),\n",
    "        transforms.Resize(spatial_size, testing),        \n",
    "        ScaleIntensityd(keys=[\"image\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    CacheDataset(\n",
    "        data=val_files,\n",
    "        transform=val_transforms,\n",
    "        cache_rate=1.0,\n",
    "    ),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label info\n",
    "target_labels = list(transforms.MapLabelsNeurite.label_mapping().values())\n",
    "n_labels = len(target_labels)\n",
    "print(\"n_labels =\", n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = n_labels + 1\n",
    "model = utils.get_model(out_channels)\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint = torch.load(model_pth)\n",
    "checkpoint = {k.replace(\"module.\", \"\"): v for k, v in checkpoint.items()}\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "post_pred = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=val_transforms,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "            device=\"cpu\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_data = first(val_loader)\n",
    "# image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
    "# print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "# # plot the slice [:, :, 80]\n",
    "# plt.figure(\"check\", (12, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.title(\"image\")\n",
    "# plt.imshow(image[:, :, 128], cmap=\"gray\")\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.title(\"label\")\n",
    "# plt.imshow(label[:, :, 128])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = first(val_loader)\n",
    "with torch.no_grad():\n",
    "    inputs, labels = (\n",
    "        check_data[\"image\"].to(device),\n",
    "        check_data[\"label\"].to(device),\n",
    "    )\n",
    "\n",
    "    check_data[\"pred\"] = sliding_window_inference(\n",
    "                inputs=inputs,\n",
    "                roi_size=patch_size,\n",
    "                sw_batch_size=1,\n",
    "                predictor=model,\n",
    "                overlap=0.5\n",
    "    )\n",
    "    post_outputs = [post_pred(i) for i in decollate_batch(check_data)]\n",
    "    pred_orig = post_outputs[0][\"pred\"].softmax(0).argmax(0)\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.title(\"pred_orig\")\n",
    "plt.imshow(pred_orig[:, :, 128].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"image\", \"label\"]\n",
    "tta_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=keys),\n",
    "        EnsureChannelFirstd(keys=keys),\n",
    "        Orientationd(keys=keys, axcodes=\"RAS\", lazy=True),\n",
    "        ResizeWithPadOrCropd(\n",
    "            keys=keys,\n",
    "            spatial_size=spatial_size,\n",
    "            lazy=True,\n",
    "        ),\n",
    "        RandZoomd(\n",
    "            keys=keys,\n",
    "            prob=1.0,\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "            min_zoom=0.75,\n",
    "            max_zoom=1.25, \n",
    "            lazy=True,\n",
    "        ),\n",
    "        RandAffined(\n",
    "            keys=keys,\n",
    "            prob=1.0,\n",
    "            rotate_range=((25 * np.pi/180,) * 3),\n",
    "            translate_range=(25),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "            lazy=True,\n",
    "        ),\n",
    "        ScaleIntensityd(keys=[\"image\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tta_loader = DataLoader(\n",
    "    CacheDataset(\n",
    "        data=val_files,\n",
    "        transform=tta_transforms,\n",
    "        cache_rate=1.0,\n",
    "    ),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = first(tta_loader)\n",
    "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, 128], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, 128])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inputs, patch_size, model, post_pred=False):\n",
    "    outputs = sliding_window_inference(\n",
    "                inputs=inputs,\n",
    "                roi_size=patch_size,\n",
    "                sw_batch_size=1,\n",
    "                predictor=model,\n",
    "                overlap=0.5\n",
    "    )\n",
    "    if post_pred:\n",
    "        outputs = [post_pred(i) for i in decollate_batch(outputs)]\n",
    "        outputs = outputs[0]\n",
    "    return outputs\n",
    "\n",
    "tt_aug = TestTimeAugmentation(\n",
    "    tta_transforms,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    inferrer_fn=lambda x: forward(x, patch_size, model),\n",
    "    device=device,\n",
    "    return_full_data=True,\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for file in np.random.choice(val_files, size=1, replace=False):\n",
    "        pred_tta_all = tt_aug(file, num_examples=16)\n",
    "        pred_tta_all = pred_tta_all.softmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tta_mean = pred_tta_all.mean(0).argmax(0)\n",
    "pred_tta_median = pred_tta_all.median(0).values.argmax(0)\n",
    "pred_tta_mode = pred_tta_all.mode(0).values.argmax(0)\n",
    "\n",
    "plt.figure(\"check\", (12, 12))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"pred_orig\")\n",
    "plt.imshow(pred_orig[:, :, 128].cpu())\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"pred_tta_mean\")\n",
    "plt.imshow(pred_tta_mean[:, :, 128].cpu())\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"pred_tta_median\")\n",
    "plt.imshow(pred_tta_median[:, :, 128].cpu())\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"pred_tta_mode\")\n",
    "plt.imshow(pred_tta_mode[:, :, 128].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "\n",
    "#     for ix, batch_data in enumerate(val_loader):\n",
    "\n",
    "#         inputs, labels = (\n",
    "#             batch_data[\"image\"].to(device),\n",
    "#             batch_data[\"label\"].to(device),\n",
    "#         )\n",
    "\n",
    "#         outputs = inference(inputs, model, patch_size=patch_size)\n",
    "#         post_outputs = [post_pred(i) for i in decollate_batch(outputs)]\n",
    "\n",
    "#         dice_metric(y_pred=post_outputs, y=labels)\n",
    "#         dice_metric_batch(y_pred=post_outputs, y=labels)\n",
    "#         break\n",
    "\n",
    "#     # aggregate the final mean dice result\n",
    "#     metric = dice_metric.aggregate().item()\n",
    "#     metric_batch = dice_metric_batch.aggregate()        \n",
    "#     # reset the status for next validation round\n",
    "#     dice_metric.reset()\n",
    "#     dice_metric_batch.reset()                        \n",
    "\n",
    "#     # print metric to terminal\n",
    "#     print(f\"METRIC={metric:.4f}\")\n",
    "#     # for i in range(0, len(metric_batch), 10): \n",
    "#     #     print( \" \" * (13 + len(str(max_epochs))) + \"|______\" + \", \"\n",
    "#     #             .join([f\"{k + i:3.0f}={v:0.3f}\".format(k, v) for k, v in enumerate(metric_batch[i:i + 10])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metric_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
